{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b536d2af-ef43-4905-8250-e80d7ce9a4db",
   "metadata": {},
   "source": [
    "# Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdfb378-09ea-4d89-8d20-495c464bd802",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6ae99b-5837-4c55-b2db-bd7cd12e27cb",
   "metadata": {},
   "source": [
    "Для начала познакомимся с этими записями. \\\n",
    "Установи библиотеку [librosa](https://librosa.org/). Это популярная библиотека для работы с аудио.\n",
    "Визуализируй аудио сигнал файла `0_1_0_1_1_1_0_0.wav` с помощью функции [librosa.display.waveshow](https://librosa.org/doc/main/generated/librosa.display.waveshow.html)\n",
    "График должен быть такой же, как показано ниже (по значениям):\n",
    "\n",
    "![waveform](../misc/images/waveform.png)\n",
    ">Для того, чтобы прослушать это аудио файл, можешь воспользоваться [IPython.display.Audio](http://ipython.org/ipython-doc/stable/api/generated/IPython.display.html#IPython.display.Audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "241e134b-bb0d-4962-ae6b-80f98f793639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Код тут"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769806f1-3206-46db-8fb9-f848dd337d64",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfefd4c-72d3-4de7-bb01-0cecd51a3be8",
   "metadata": {},
   "source": [
    "Для классификации обычно использует не просто аудио сигнал, а его частотно-временное представление. Для этого сигнал требуется\n",
    "преобразовать с помощью [оконного преобразования Фурье](https://clck.ru/34JnZD).\n",
    "С помощью функции [librosa.display.specshow](https://librosa.org/doc/main/generated/librosa.display.specshow.html) \n",
    "выведи спектрограмму сигнала. \\\n",
    "График должен быть такой же, как показано ниже (по значениям):\n",
    "![sftp](../misc/images/sftp.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb55dc73-3ef5-4839-931d-5da9989a8af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Код тут"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ba3fcc-00ba-4940-a45c-8fd645210773",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33985db5-672f-4b54-80e2-d9086d3ae24b",
   "metadata": {},
   "source": [
    "C помощью функции [load_dataset](code-samples/audio_utils.py) загрузи датасет. \\\n",
    "Раздели его на train и test c параметрами `test_size=0.2`, `random_state=42`. \\\n",
    "Выведи количество файлов в train и test частях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3b8e720-0ea7-455f-a700-c0adf3f9584d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(directory: str):\n",
    "    sr = None\n",
    "    X, labels, files = [], [], []\n",
    "    for f in glob(directory + \"/*.wav\"):\n",
    "        filename = os.path.basename(f)\n",
    "        name = filename[:-4]\n",
    "        y = [int(label) for label in name.split(\"_\")]\n",
    "        x, sr = librosa.load(f)\n",
    "        X.append(x)\n",
    "        labels.append(y)\n",
    "        files.append(filename)\n",
    "\n",
    "    return X, labels, sr, files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08bc6d2b-7aae-48b9-898b-acc1b8f808d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Код тут"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37448af8-8629-4b6a-ba9e-a5b6474d81d5",
   "metadata": {},
   "source": [
    "## Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e918fb1-4f37-4336-b4d4-20b4f4fb77d1",
   "metadata": {},
   "source": [
    "Наши аудио записи содержат как речь человека, так и молчание. Для каждой записи нам нужно определить сегменты записи, \n",
    "где человек молчит, а где произносит слова. \\\n",
    "Эта задача называется [Voice Activity Detection (VAD)](https://ru.wikipedia.org/wiki/Voice_Activity_Detection).\n",
    "Придумайте или найдите метод, по которому можно распознавать участки с речью на аудио записи.\n",
    "\n",
    "Например:\n",
    "Запись '0_0_0_1_0_1_1_0.wav' содержит 137592 отсчетов. Сегменты с речью для этой записи (Отмечены красным):\n",
    "[[23996, 32539],\n",
    " [35410, 44925],\n",
    " [49493, 57410],\n",
    " [60458, 68635],\n",
    " [73308, 81278],\n",
    " [84001, 91942],\n",
    " [97381, 104166],\n",
    " [109018, 115573]] \n",
    "![sftp](../misc/images/vad.png)\n",
    "\n",
    "Выведи несколько примеров работы твоего VAD-алгоритма, по аналогии с примером, для других аудио записей. Попробуй добиться\n",
    "наилучшего качества нахождения речи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "143a8574-daf7-4918-b86a-32f4caa21d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Код тут"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e7b192-d6f0-4259-959c-833f4ee26cb5",
   "metadata": {},
   "source": [
    "## Task 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ccfb93-41b9-4b86-b039-753a9c65def6",
   "metadata": {},
   "source": [
    "После того как мы узнали сегменты аудио с речью, то можно перейти к самой задаче классификации. \\\n",
    "Внимательно изучи функцию [make_dataset](code-samples/audio_utils.py). С помощью этой функции cгенерируй X, Y для train и test выборок.\n",
    "Затем попробуй обучить различные классификаторы. Например, SVM или LogisticRegression.\n",
    "Измерь точность (accuracy) классификации на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ff76a1e-6d51-4f9e-be04-f2f158369e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(samples, labels, vad_segments):\n",
    "    \"\"\"\n",
    "\n",
    "    :param samples: Список аудио сигналов\n",
    "    :param labels: Список меток (Например для файла '0_0_0_1_0_1_1_0.wav': [0, 0, 0, 1, 0, 1, 1, 0])\n",
    "    :param vad_segments: Список сегментов для каждого аудио сигнала вида:\n",
    "        [\n",
    "            [[23996, 32539], [35410, 44925], ...,],\n",
    "            [[22141, 30259], [34917, 42695], ...,],\n",
    "            ...\n",
    "        ]\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    # Проходим по каждому аудио сигналу\n",
    "    for sample in range(len(samples)):\n",
    "        # В аудио сигнале проходим по каждому сегменту с речью\n",
    "        for segment in range(len(vad_segments[sample]) - 1):\n",
    "            start = vad_segments[sample][segment][0]  # Начало сегмента\n",
    "            stop = vad_segments[sample][segment][1]  # Конец сегмента\n",
    "            voice = samples[sample][start:stop]  # Отрезаем сегмент с речью из аудио сигнала и применяем stft\n",
    "            stft = librosa.stft(voice).mean(axis=1)\n",
    "            stft_db = librosa.amplitude_to_db(abs(stft))\n",
    "\n",
    "            X.append(stft_db)  # Добавляем спектрограмму с речью\n",
    "            y.append(labels[sample][segment])  # Добавляем метку для этой спектрограммы\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2569c22-78f3-4af6-985f-c4d44cf4a037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Код тут"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
